# S3 - Simple Storage Service
* infinitely scaling storage
* objects (files) stored in buckets (directories)

## Buckets
* buckets must have a globally unique name
* buckets are defined at the region level
* naming convention:
  - no uppercase
  - no underscore
  - 3-63 characters long
  - not an ip
  - must start with lowercase or number

## Files
* objects have a Key. Key is the _full_ path
  - my_bucket/_myfile.txt_
  - my_bucket/_my_folder/another_folder/my_file.txt_
  - no concept of directories within buckets - just very long names which contain / (slashes)
  - object values are the content of the body
    - max size is 5TB
    - if uploading more than 5GB must use multi-part upload
  - metadata (list of text key/value pairs - system or user metadata)
  - tags (unicode key/value pairs - up to 10) - useful for security/lifecycle
  - Version ID (if versioning enabled)
  - If file is not publicly accesible you can open it from S3 Console but not following the public link

## Versioning
* enabled at bucket level
* same key overwrite will increment the "version"
* best practice to version your buckets
  - protect against unintended deletes
  - easy roll back to previous version
* any file that is not versioned prior to enabling versioning will have version "null"
* when deleting it places a _delete marker_ on the file and creates a new version of the file (with the delete marker)

## Encryption
* 4 methods for encrypting in S3
  - SSE-S3: encrypts objects using keys handled and managed by AWS
    - object is encrypted server side
    - AES-256 encryption
    - must set header "x-amz-servers-side-encryption":"AES256"
  - SSE-KMS: leverage AWS KMS (Key management service) to manage encryption keys
    - advantages: user control + audit trail
    - must set header "x-amz-servers-side-encryption":"aws:kms"
    - AWS manages keys
    - you have control of the key rotation policy
  - SSE-C: when you want to manage your own encryption keys
    - SSE using data keys fully managed by the customer outside of AWS
    - AWS S3 does not store the encryption key you provided
    - HTTPS must be used
    - Encryption key must be provided in HTTP headers, for every http request made
  - Client Side Encryption
    - Client library such as the AWS S3 Encryption Client
    - Client must encrypt data themselves before sending to S3
    - Client must decrypt data themselves when retrieving from S3
    - Customer fully manages the keys and the encryption cycle

* Encryption in transit (SSL)
  - HTTP endpoint: non encrypted
  - HTTPS endpoint : encryption in flight

## Security
* User based
  - IAM policies - which API calls should be allowed for a specific user from IAM console
* Resource Based
  - Bucket policies - bucket wide rules from the S3 Console - allow cross account
    - JSON based policies
      - Resources: buckets and objects
      - Actions: set of API to Allow or Deny
      - Effect: ALlow/Deny
      - Principal: The account or user to apply policy to
    - Use S3 Bucket for policy to:
      - grant public access to the bucket
      - for objects to be encrypted at upload
      - grant access to another account (Cross Account)
  - Object ACL - Object Access Control List (ACL) - finer grain
  - Bucket ACL - Bucket Access Control List (ACL) - less common
* Other
  - Supports VPC endpoints (instances in VPC without internet access can still talk to vpc endpoint)
  - Logging and Audit:
    - S3 access logs can be stored in other S3 Bucket
    - API call can be logged in AWS CloudTrail
  - User Security
    - MFA can be required in versioned buckets to delete objects
    - Signed URLS: URLs thar are valid only for a limited time (premium video service for logged in users)

## S3 Websites
* S3 can host static websites and have them accessible on the www
* Website URL will be:
  - bucketname.s3-website-AWSREGION.amazonaws.com
  - bucketname.s3-website.AWSREGION.amazonaws.com
* If you get a 403 (forbidden error), make sure the bucket policy allows public reads

## S3 Cors
* If you request data from another S3 bucket, you need to enable CORS
* Cross Origin Resource Sharing allows you to limit the number of websites that can request your files in S3 (and limit
  your costs)

## S3 Consistency model
* Read after write consistency for PUTS of new objects
  - as soon as an object is written, we can retrieve it (PUT 200 -> GET 200)
  - this is true _EXCEPT_ if we did a GET before to see if the object existed (GET 404 -> PUT 200 -> GET 404) -
    _eventually consistent_
* Eventual consistency for DELETES and PUTS of existing objects
  - if we read an object after updating, we might get the older version
    (PUT 200 -> PUT 200 -> GET 200 (might be older version))
  - if we delete an object, might still be able to retrieve it for a short time
    (DELETE 200 -> GET 200)
