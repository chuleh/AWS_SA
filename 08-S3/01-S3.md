# S3 - Simple Storage Service

* infinitely scaling storage
* objects (files) stored in buckets (directories)
* mostly used for:
  * backup and storage
  * disaster recovery
  * archive
  * hybrid cloud storage
  * app hosting
  * media hosting
  * data lakes * big data analytics
  * software delivery
  * static website

## Buckets

* buckets must have a globally unique name (unique among all accounts that exist in AWS)
* buckets are defined at the region level || however service is global => see same bucket across all regions in one view
* naming convention:
  * no uppercase
  * no underscore
  * 3-63 characters long
  * not an ip
  * must start with lowercase or number

## Files

* objects have a Key. Key is the *full* path
  * my_bucket/*myfile.txt*
  * my_bucket/*my_folder/another_folder/my_file.txt*
  * *no concept of directories within buckets - just very long names which contain / (slashes)*
  * object values are the content of the body
    * max size is 5TB
    * if uploading more than 5GB must use multi-part upload
  * metadata (list of text key/value pairs - system or user metadata)
  * tags (unicode key/value pairs - up to 10) - useful for security/lifecycle
  * Version ID (if versioning enabled)
  * If file is not publicly accesible you can open it from S3 Console but not following the public link

## Security

* User based
  * IAM policies - which API calls should be allowed for a specific user from IAM console
  * an IAM principal can access an S3 object if:
    * the users IAM permissions *ALLOW* it *OR* the resource policy allows it *AND* there's no explicity *DENY*
* Resource Based
  * Bucket policies - bucket wide rules from the S3 Console - allow cross account
    * JSON based policies
      * Resources: buckets and objects
      * Effect: ALlow/Deny
      * Actions: set of API to Allow or Deny
      * Principal: The account or user to apply policy to
    * Use S3 Bucket for policy to:
      * grant public access to the bucket
      * for objects to be encrypted at upload
      * grant access to another account (Cross Account)
  * Object ACL - Object Access Control List (ACL) - finer grain
  * Bucket ACL - Bucket Access Control List (ACL) - less common
* Bucket settings for Block Public Access
  * created by AWS to prevent data leaks
  * if bucket should never be public => leave them on
  * can be set at account level
* Other
  * Supports VPC endpoints (instances in VPC without internet access can still talk to vpc endpoint)
  * Logging and Audit:
    * S3 access logs can be stored in other S3 Bucket
    * API call can be logged in AWS CloudTrail
  * User Security
    * MFA can be required in versioned buckets to delete objects
    * Signed URLS: URLs thar are valid only for a limited time (premium video service for logged in users)

## S3 static websites

* S3 can host static websites and have them accessible on the www
* Website URL will be:
  * bucketname.s3-website-AWSREGION.amazonaws.com
  * bucketname.s3-website.AWSREGION.amazonaws.com
* If you get a 403 (forbidden error), make sure the bucket policy allows public reads

## Versioning

* enabled at bucket level
* same key overwrite will increment the "version"
* best practice to version your buckets
  * protect against unintended deletes
  * easy roll back to previous version
* any file that is not versioned prior to enabling versioning will have version "null"
* suspending versioning *will not* delete previous versions
* when deleting it places a *delete marker* on the file and creates a new version of the file (with the delete marker)
* to effectively delete => delete the one with the delete marker

## Replication

* After you enable replication *only* new objects are replicated
* You can replicate existing objects using *S3 Batch Replication*
* For *DELETE* operations
  * *can* replicate delete markers from source to target (optional setting)
  * deletions with a version ID are not replicated (to avoid malicious deletes) => *permanently deletes* are not replicated
* no chaining of replication
  * bucket 1 replicates into bucket 2 / bucket 2 into bucket 3 / objects created into bucket 1 *wont* replicate into bucket 3
* SRR - Single Region Replication || CRR - Cross Region Replication
  * async replication between buckets (eu-west-1 --> us-east-1)
  * *must* enable versioning between source and destination buckets
  * buckets can be between different accounts
  * must have proper IAM permissions to S3
* Use cases:
  * CRR - compliance / lower latency access / replication across accounts
  * SRR - log aggregation / live replication between prod and test accounts

## S3 Storage Classes

* S3 standard - general purpose
  * High Durability of objects across multiple AZ (11x9 durability)
  * 99.99 Availability over a given year
  * used for frequently accessed data
  * low latency and high throughput
  * Can sustain 2 concurrent facility failures
  * Use Cases: Big Data Analytics - mobile & gaming applications, content distribution
* S3 Standard-Infrequent Access (IA)
  * Suitable for data that is less frequently accessed but requires rapid access when needed
  * High durability (11x9) of objects across multiple AZs
  * 99.9 availability
  * Low cost compared to S3 Standard
  * Can sustain 2 concurrent facility failures
  * Use cases: data store for disaster recovery, backups
* S3 One Zone-Infrequent Access
  * Same as IA but data stored in a single AZ
  * High Durability (11x9) of objects in a single AZ; data lost when AZ is destroyed
  * 99.5 Availability
  * Low latency and high throughput performance
  * Supports SSL for data at transit and encryption at rest
  * Low cost compared to IA (by 20%)
  * Use cases: storing secondary backup of copies of on-prem data, storing data you can recreate
* Amazon S3 Glacier Storage Classes
  * low cost object storage meant for archiving/backup
  * pricing: price for storage + object retrieval cost
  * tiers:
    * Amazon S3 Glacier instant retrieval
      * millisecond retrieval - great for data accessed once a quarter
      * minimum storage duration of 90 days
    * Amazon S3 Glacier Flexible Retrieva (formerly Amazon Glacier)
      * Low cost object storage meant for archiving / backup
      * Data is retained for the longer team (10s of years)
      * Alternative to on-prem magnetic tape storage
      * 11x9 durability
      * Cost per storage per month ($0.004 / gb) + retrieval cost
        * 3 retrieval options
          * Expedited (1 to 5 minutes)
          * Standard (3 to 5 hours)
          * Bulk (5 to 12 hours)
      * Each item in Glacier is called *Archive* (up to 40tb)
      * Archives are stored in *Vaults*
      * Minimum storage duration of 90 days
    * Amazon Glacier Deep Archive
      * Long term storage
      * Cheaper
      * Retrieval
        * Standard (12 hours)
        * Bulk (48h hours)
        * Minimum storage duration of 180 days

## S3 Intelligent Tiering

* Same low latency and high throughput performance of S3 standard
* Small monthly monitoring and auto-tiering fee
* Automatically moves objects between two access tiers based on changing access patterns
  * Frequent Access Tier (automatic): default tier
  * Infrequent Access Tier (automatic): objects not accessed for 30 days
  * Archive Instant Access Tier (automatic): objects not accessed for 90 days
  * Archive Access Tier (optional): configurable from 90 to +700 days
  * Deep Archive Access Tier (optional): configurable from 180 days to +700 days
* High Durability of objects across multiple AZ (11x9 durability)
* Resilient against events that impact an entire AZ
* Designed for 99.9 availability over a given year
* *NO* retrieval charges in Intelligent-Tiering
* S3 Reduced Redundancy Storage (deprecated - omitted)
